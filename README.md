# Entrenamiento de Large Language Models (LLM) üöÄ

Bienvenido al repositorio donde exploraremos c√≥mo entrenar Large Language Models (LLM) utilizando herramientas y recursos open source. Aqu√≠ encontrar√°s gu√≠as paso a paso, desde la configuraci√≥n inicial hasta el entrenamiento y la implementaci√≥n de modelos de lenguaje de gran tama√±o. üìö‚ú®

## ¬øQu√© Encontrar√°s Aqu√≠? üßê

- **Instrucciones de Configuraci√≥n**: C√≥mo preparar tu entorno de desarrollo para trabajar con LLMs.
- **Gu√≠as de Entrenamiento**: Aprende a entrenar tus propios modelos LLM con datos personalizados.
- **Uso de Entornos Gratuitos**: Maximiza recursos con plataformas gratuitas como Google Colab y Kaggle Kernels.
- **Modelos Open Source**: Descubre c√≥mo utilizar modelos open source disponibles para tus proyectos.
- **Optimizaci√≥n de Modelos**: Consejos y trucos para afinar tus modelos y mejorar su rendimiento.

## Comenzando üöÄ

Para empezar, aseg√∫rate de tener una cuenta de GitHub y acceso a plataformas que ofrecen entornos de desarrollo gratuitos como Google Colab o Kaggle.

### Pre-requisitos üìã

- Python 3.6 o superior
- Pip para manejar paquetes de Python
- Acceso a Google Colab o Kaggle para entornos de desarrollo gratuitos
- Cuenta en huggingface.co, es gratuito y se pueden subir y desplegar nuestros modelos ahi.
- Opcional: Cuenta en wandb, sirve para guardar las metricas de nuestros trains (entrenamientos), super util.
- Mucha paciencia! ya que al ser algo nuevo hay poca informacion, poco soporte, las librerias cambian y los codigos dejan de andar, etc!

## Contribuir ü§ù

¬øTe interesa contribuir a este proyecto? ¬°Tu ayuda es bienvenida! Aqu√≠ hay algunas maneras en que puedes contribuir:

- **Mejoras y sugerencias**: Si tienes ideas para mejorar este proyecto, no dudes en abrir un issue o crear un Pull Request.
- **Documentaci√≥n**: Ay√∫danos a mejorar o traducir la documentaci√≥n.
- **Comparte tu experiencia**: Si usas este proyecto para entrenar tus propios modelos, ¬°comp√°rtelo con la comunidad!

## Expresiones de Gratitud üéÅ

Agradecemos sinceramente a todos los que contribuyen a este proyecto. Queremos mostrarte nuestro agradecimiento:

- Comparte este proyecto con otros üì¢.
- Invita una cerveza üç∫ o un caf√© ‚òï a alguien del equipo.
- Env√≠a un agradecimiento p√∫blico ü§ì.

## La Importancia de una Red de Hispanohablantes en el Desarrollo de IA Gratuita üåé

Crear una red de hispanohablantes dedicados al desarrollo de Inteligencia Artificial (IA) gratuita es fundamental para democratizar el acceso a la tecnolog√≠a y asegurar que las comunidades de habla hispana no se queden atr√°s en la carrera tecnol√≥gica global. Al colaborar y compartir conocimientos, recursos y modelos en espa√±ol, podemos:

- **Cerrar la brecha tecnol√≥gica**: Asegurarnos de que los avances en IA sean accesibles y √∫tiles para todos, independientemente del idioma que hablen.
- **Fomentar la innovaci√≥n**: Al trabajar juntos, podemos impulsar la innovaci√≥n y crear soluciones que aborden las necesidades espec√≠ficas de nuestras comunidades.
- **Promover la inclusi√≥n**: Crear tecnolog√≠a en espa√±ol es un paso vital hacia la inclusi√≥n de millones de hispanohablantes en todo el mundo.

## Informaci√≥n Personal üì¨

Para cualquier consulta, colaboraci√≥n o simplemente para conectar, aqu√≠ tienes mis datos de contacto:

- **Email**: [eugeniokuke@gmail.com](mailto:eugeniokuke@gmail.com)
- **LinkedIn**: [Eugenio Schiavoni](https://www.linkedin.com/in/eugenio-schiavoni/)
- **Kaggle**: [eugeniokukes](https://www.kaggle.com/code/eugeniokukes)



# Curso de Maxime Labonne de LLMs (Gracias Maxime) al espa√±ol.

# Matem√°ticas para Aprendizaje Autom√°tico

Antes de dominar el aprendizaje autom√°tico, es importante comprender los conceptos matem√°ticos fundamentales que impulsan estos algoritmos.

## √Ålgebra Lineal:

Es crucial para entender muchos algoritmos, especialmente aquellos utilizados en aprendizaje profundo. Los conceptos clave incluyen vectores, matrices, determinantes, valores y vectores propios, espacios vectoriales y transformaciones lineales.

## C√°lculo:

Muchos algoritmos de aprendizaje autom√°tico involucran la optimizaci√≥n de funciones continuas, lo que requiere un entendimiento de derivadas, integrales, l√≠mites y series. El c√°lculo multivariable y el concepto de gradientes tambi√©n son importantes.

## Probabilidad y Estad√≠stica:

Son cruciales para entender c√≥mo los modelos aprenden de los datos y hacen predicciones. Los conceptos clave incluyen teor√≠a de la probabilidad, variables aleatorias, distribuciones de probabilidad, expectativas, varianza, covarianza, correlaci√≥n, pruebas de hip√≥tesis, intervalos de confianza, estimaci√≥n de m√°xima verosimilitud e inferencia Bayesiana.

## üìö Recursos:

- [3Blue1Brown - La Esencia del √Ålgebra Lineal](https://www.youtube.com/playlist?list=PLZHQObOWTQDPD3MizzM2xVFitgF8hE_ab): Serie de videos que ofrecen una intuici√≥n geom√©trica de estos conceptos.
- [StatQuest con Josh Starmer - Fundamentos de Estad√≠sticas](https://statquest.org/): Ofrece explicaciones simples y claras para muchos conceptos estad√≠sticos.
- [AP Statistics Intuition por Ms Aerin](https://aerinmv.github.io/stats_in_pictures/index.html): Lista de art√≠culos en Medium que proporcionan la intuici√≥n detr√°s de cada distribuci√≥n de probabilidad.
- [√Ålgebra Lineal Inmersiva](https://immersivemath.com/ila/index.html): Otra interpretaci√≥n visual del √°lgebra lineal.
- [Khan Academy - √Ålgebra Lineal](https://www.khanacademy.org/math/linear-algebra): Genial para principiantes ya que explica los conceptos de manera muy intuitiva.
- [Khan Academy - C√°lculo](https://www.khanacademy.org/math/calculus-1): Un curso interactivo que cubre todos los fundamentos del c√°lculo.
- [Khan Academy - Probabilidad y Estad√≠stica](https://www.khanacademy.org/math/statistics-probability): Presenta el material de forma f√°cil de entender.

# Python para Aprendizaje Autom√°tico

Python es un lenguaje de programaci√≥n poderoso y flexible que es especialmente bueno para el aprendizaje autom√°tico, gracias a su legibilidad, consistencia y robusto ecosistema de librer√≠as de ciencia de datos.

## Fundamentos de Python:

La programaci√≥n en Python requiere un buen entendimiento de la sintaxis b√°sica, tipos de datos, manejo de errores y programaci√≥n orientada a objetos.

## Librer√≠as de Ciencia de Datos:

Incluye familiaridad con NumPy para operaciones num√©ricas, Pandas para manipulaci√≥n y an√°lisis de datos, Matplotlib y Seaborn para visualizaci√≥n de datos.

## Preprocesamiento de Datos:

Esto implica escalado y normalizaci√≥n de caracter√≠sticas, manejo de datos faltantes, detecci√≥n de outliers, codificaci√≥n de datos categ√≥ricos y divisi√≥n de datos en conjuntos de entrenamiento, validaci√≥n y pruebas.

## Librer√≠as de Aprendizaje Autom√°tico:

La competencia con Scikit-learn, una librer√≠a que ofrece una amplia selecci√≥n de algoritmos de aprendizaje supervisado y no supervisado, es vital. Entender c√≥mo implementar algoritmos como regresi√≥n lineal, regresi√≥n log√≠stica, √°rboles de decisi√≥n, bosques aleatorios, k-nearest neighbors (K-NN) y agrupamiento K-means es importante. T√©cnicas de reducci√≥n de dimensionalidad como PCA y t-SNE tambi√©n son √∫tiles para visualizar datos de alta dimensi√≥n.

## üìö Recursos:

- [Real Python](https://realpython.com/): Un recurso comprensivo con art√≠culos y tutoriales tanto para conceptos b√°sicos como avanzados de Python.
- [freeCodeCamp - Aprender Python](https://www.youtube.com/watch?v=rfscVS0vtbw): Video largo que proporciona una introducci√≥n completa a todos los conceptos fundamentales en Python.
- [Python Data Science Handbook](https://jakevdp.github.io/PythonDataScienceHandbook/): Libro digital gratuito que es un gran recurso para aprender pandas, NumPy, Matplotlib y Seaborn.
- [freeCodeCamp - Aprendizaje Autom√°tico para Todos](https://www.youtube.com/watch?v=I74ymkoNTnw): Introducci√≥n pr√°ctica a diferentes algoritmos de aprendizaje autom√°tico para principiantes.
- [Udacity - Introducci√≥n al Aprendizaje Autom√°tico](https://www.udacity.com/course/intro-to-machine-learning--ud120): Curso gratuito que cubre PCA y varios otros conceptos de aprendizaje autom√°tico.

# Redes Neuronales

Las redes neuronales son una parte fundamental de muchos modelos de aprendizaje autom√°tico, particularmente en el √°mbito del aprendizaje profundo. Para utilizarlas eficazmente, es esencial tener un entendimiento comprensivo de su dise√±o y mec√°nicas.

## Fundamentos:

Esto incluye entender la estructura de una red neuronal como capas, pesos, sesgos y funciones de activaci√≥n (sigmoide, tanh, ReLU, etc.)

## Entrenamiento y Optimizaci√≥n:

Familiar√≠zate con la retropropagaci√≥n y diferentes tipos de funciones de p√©rdida, como el Error Cuadr√°tico Medio (MSE) y Entrop√≠a Cruzada. Entiende varios algoritmos de optimizaci√≥n como Descenso de Gradiente, Descenso de Gradiente Estoc√°stico, RMSprop y Adam.

## Sobreadjuste:

Entiende el concepto de sobreadjuste (donde un modelo rinde bien en datos de entrenamiento pero mal en datos no vistos) y aprende varias t√©cnicas de regularizaci√≥n (dropout, regularizaci√≥n L1/L2, parada temprana, aumento de datos) para prevenirlo.

## Implementa un Perceptr√≥n Multicapa (MLP):

Construye un MLP, tambi√©n conocido como una red completamente conectada, usando PyTorch.

## üìö Recursos:

- [3Blue1Brown - ¬øPero qu√© es una Red Neuronal?](https://www.youtube.com/watch?v=aircAruvnKk): Este video ofrece una explicaci√≥n intuitiva de las redes neuronales y su funcionamiento interno.
- [freeCodeCamp - Curso Intensivo de Aprendizaje Profundo](https://www.youtube.com/watch?v=VyWAvY2CF9c): Este video introduce de manera eficiente todos los conceptos m√°s importantes en aprendizaje profundo.
- [Fast.ai - Aprendizaje Profundo Pr√°ctico](https://www.fast.ai/): Curso gratuito dise√±ado para personas con experiencia en programaci√≥n que quieren aprender sobre aprendizaje profundo.
- [Patrick Loeber - Tutoriales de PyTorch](https://www.youtube.com/playlist?list=PLqnslRFeH2UrcDBWF5mfPGpqQDSta6VK4): Serie de videos para principiantes completos para aprender sobre PyTorch.

# Procesamiento de Lenguaje Natural (NLP)

NLP es una rama fascinante de la inteligencia artificial que cierra la brecha entre el lenguaje humano y la comprensi√≥n por parte de la m√°quina. Desde el procesamiento de texto simple hasta la comprensi√≥n de matices ling√º√≠sticos, NLP juega un papel crucial en muchas aplicaciones como traducci√≥n, an√°lisis de sentimientos, chatbots y mucho m√°s.

## Preprocesamiento de Texto:

Aprende varios pasos de preprocesamiento de texto como la tokenizaci√≥n (dividir el texto en palabras o frases), stemming (reducir las palabras a su forma ra√≠z), lematizaci√≥n (similar al stemming pero considera el contexto), eliminaci√≥n de palabras de parada, etc.

## T√©cnicas de Extracci√≥n de Caracter√≠sticas:

Familiar√≠zate con t√©cnicas para convertir datos de texto en un formato que pueda ser entendido por algoritmos de aprendizaje autom√°tico. Los m√©todos clave incluyen Bolsa de Palabras (BoW), Frecuencia de T√©rmino-Frecuencia Inversa de Documento (TF-IDF) y n-gramas.

## Incrustaciones de Palabras:

Las incrustaciones de palabras son un tipo de representaci√≥n de palabras que permite que palabras con significados similares tengan representaciones similares. Los m√©todos clave incluyen Word2Vec, GloVe y FastText.

## Redes Neuronales Recurrentes (RNNs):

Entiende el funcionamiento de las RNNs, un tipo de red neuronal dise√±ada para trabajar con datos secuenciales. Explora las LSTMs y GRUs, dos variantes de RNN capaces de aprender dependencias a largo plazo.

## üìö Recursos:

- [RealPython - NLP con spaCy en Python](https://realpython.com/nlp-with-spacy-python/): Gu√≠a exhaustiva sobre la librer√≠a spaCy para tareas de NLP en Python.
- [Kaggle - Gu√≠a de NLP](https://www.kaggle.com/learn/natural-language-processing): Algunos cuadernos y recursos para una explicaci√≥n pr√°ctica de NLP en Python.
- [Jay Alammar - La Ilustraci√≥n de Word2Vec](https://jalammar.github.io/illustrated-word2vec/): Una buena referencia para entender la famosa arquitectura Word2Vec.
- [Jake Tae - RNN de PyTorch desde Cero](https://www.youtube.com/playlist?list=PLBAGcD3siRDjBU8sKRk0zX9pMz9qeVxud): Implementaci√≥n pr√°ctica y simple de modelos RNN, LSTM y GRU en PyTorch.
- [Blog de colah - Comprendiendo las Redes LSTM](https://colah.github.io/posts/2015-08-Understanding-LSTMs/): Un art√≠culo m√°s te√≥rico sobre la red LSTM.

- # üßë‚Äçüî¨ El Cient√≠fico LLM

Esta secci√≥n del curso se centra en aprender c√≥mo construir los mejores LLM posibles utilizando las t√©cnicas m√°s recientes.

## 1. La Arquitectura LLM

Aunque no se requiere un conocimiento profundo sobre la arquitectura Transformer, es importante tener un buen entendimiento de sus entradas (tokens) y salidas (logits). El mecanismo de atenci√≥n b√°sico es otro componente crucial para dominar, ya que se introducen versiones mejoradas m√°s adelante.

### Vista de alto nivel:

Revisar la arquitectura Transformer codificador-decodificador, y m√°s espec√≠ficamente la arquitectura GPT de solo decodificador, que se utiliza en todos los LLM modernos.

### Tokenizaci√≥n:

Entender c√≥mo convertir datos de texto crudo en un formato que el modelo pueda entender, lo que implica dividir el texto en tokens (generalmente palabras o subpalabras).

### Mecanismos de atenci√≥n:

Comprender la teor√≠a detr√°s de los mecanismos de atenci√≥n, incluyendo la autoatenci√≥n y la atenci√≥n por producto escalar, que permite al modelo enfocarse en diferentes partes de la entrada al producir una salida.

### Generaci√≥n de texto:

Aprender sobre las diferentes formas en que el modelo puede generar secuencias de salida. Las estrategias comunes incluyen la decodificaci√≥n codiciosa, b√∫squeda por haz, muestreo top-k y muestreo de n√∫cleo.

#### üìö Referencias:

- [El Transformer Ilustrado por Jay Alammar](https://jalammar.github.io/illustrated-transformer/): Una explicaci√≥n visual e intuitiva del modelo Transformer.
- [El GPT-2 Ilustrado por Jay Alammar](https://jalammar.github.io/illustrated-gpt2/): A√∫n m√°s importante que el art√≠culo anterior, se centra en la arquitectura GPT, que es muy similar a la de Llama.
- [Visualizaci√≥n LLM por Brendan Bycroft](https://transformer.huggingface.co/): Incre√≠ble visualizaci√≥n 3D de lo que sucede dentro de un LLM.
- [nanoGPT por Andrej Karpathy](https://www.youtube.com/watch?v=SnR_aSp3Rsw): Un video de 2 horas en YouTube para reimplementar GPT desde cero (para programadores).
- [¬øAtenci√≥n? ¬°Atenci√≥n! por Lilian Weng](https://lilianweng.github.io/lil-log/2018/06/24/attention-attention.html): Introduce la necesidad de atenci√≥n de una manera m√°s formal.
- [Estrategias de Decodificaci√≥n en LLMs](https://huggingface.co/blog/how-to-generate): Proporciona c√≥digo y una introducci√≥n visual a las diferentes estrategias de decodificaci√≥n para generar texto.

## 2. Construyendo un Conjunto de Datos de Instrucciones

Si bien es f√°cil encontrar datos crudos de Wikipedia y otros sitios web, es dif√≠cil recolectar pares de instrucciones y respuestas en la naturaleza. Como en el aprendizaje autom√°tico tradicional, la calidad del conjunto de datos influir√° directamente en la calidad del modelo, por lo que podr√≠a ser el componente m√°s importante en el proceso de ajuste fino.

### Conjunto de datos tipo Alpaca:

Generar datos sint√©ticos desde cero con la API de OpenAI (GPT). Puedes especificar semillas y prompts del sistema para crear un conjunto de datos diverso.

### T√©cnicas avanzadas:

Aprender c√≥mo mejorar conjuntos de datos existentes con Evol-Instruct, c√≥mo generar datos sint√©ticos de alta calidad como en los papeles de Orca y phi-1.

### Filtrado de datos:

T√©cnicas tradicionales que involucran regex, eliminaci√≥n de duplicados cercanos, enfoc√°ndose en respuestas con un alto n√∫mero de tokens, etc.

### Plantillas de prompts:

No hay una verdadera forma est√°ndar de formatear instrucciones y respuestas, por lo que es importante saber sobre las diferentes plantillas de chat, como ChatML, Alpaca, etc.

#### üìö Referencias:

- [Preparando un Conjunto de Datos para Ajuste Fino de Instrucciones por Thomas Capelle](https://towardsdatascience.com/structuring-a-prompted-fine-tuning-dataset-5650d7f8db1b): Exploraci√≥n de los conjuntos de datos Alpaca y Alpaca-GPT4 y c√≥mo formatearlos.
- [Generando un Conjunto de Datos de Instrucciones Cl√≠nicas por Solano Todeschini](https://github.com/todeschinirene/gpt4-med-dialog): Tutorial sobre c√≥mo crear un conjunto de datos de instrucciones sint√©ticas usando GPT-4.
- [GPT 3.5 para Clasificaci√≥n de Noticias por Kshitiz Sahay](https://github.com/kshitizsahay/GPT3.5-for-news-classification): Usar GPT 3.5 para crear un conjunto de datos de instrucciones para ajustar fino Llama 2 para clasificaci√≥n de noticias.
- [Creaci√≥n de Conjuntos de Datos para Ajuste Fino de LLM](https://github.com/huggingface/transformers/blob/master/examples/question-answering/utils_qa.py): Cuaderno que contiene algunas t√©cnicas para filtrar un conjunto de datos y subir el resultado.
- [Plantilla de Chat por Matthew Carrigan](https://huggingface.co/blog/how-to-build): P√°gina de Hugging Face sobre plantillas de prompts.

## 3. Modelos de Preentrenamiento

El preentrenamiento es un proceso muy largo y costoso, por lo que este no es el enfoque de este curso. Es bueno tener alg√∫n nivel de entendimiento de lo que sucede durante el preentrenamiento, pero no se requiere experiencia pr√°ctica.

### Tuber√≠a de Datos:

El preentrenamiento requiere conjuntos de datos enormes (por ejemplo, Llama 2 fue entrenado en 2 billones de tokens) que necesitan ser filtrados, tokenizados y agrupados con un vocabulario predefinido.

### Modelado de Lenguaje Causal:

Aprender la diferencia entre el modelado de lenguaje causal y enmascarado, as√≠ como la funci√≥n de p√©rdida utilizada en este caso. Para un preentrenamiento eficiente, aprender m√°s sobre Megatron-LM o gpt-neox.

### Leyes de Escalado:

Las leyes de escalado describen el rendimiento esperado del modelo basado en el tama√±o del modelo, tama√±o del conjunto de datos y la cantidad de c√°lculo utilizado para el entrenamiento.

### Computaci√≥n de Alto Rendimiento:

Fuera del alcance aqu√≠, pero m√°s conocimiento sobre HPC es fundamental si est√°s planeando crear tu propio LLM desde cero (hardware, carga de trabajo distribuida, etc.).

#### üìö Referencias:

- [LLMDataHub por Junhao Zhao](https://github.com/junhaoz/LLMpapers): Lista curada de conjuntos de datos para preentrenamiento, ajuste fino y RLHF.
- [Entrenando un Modelo de Lenguaje Causal desde Cero por Hugging Face](https://github.com/huggingface/transformers/blob/master/examples/pytorch/language-modeling/run_megatron_gpt2.py): Preentrena un modelo GPT-2 desde cero usando la librer√≠a transformers.
- [TinyLlama por Zhang et al.](https://github.com/LLM-team/TinyLLAMA): Consulta este proyecto para obtener una buena comprensi√≥n de c√≥mo se entrena un modelo Llama desde cero.
- [Modelado de Lenguaje Causal por Hugging Face](https://huggingface.co/blog/causal-language-modeling): Explica la diferencia entre el modelado de lenguaje causal y enmascarado y c√≥mo ajustar fino r√°pidamente un modelo DistilGPT-2.
- [Implicaciones Salvajes de Chinchilla por nostalgebraist](https://nostalgebraist.tumblr.com/post/622045615543945472/scaling-laws): Discute las leyes de escalado y explica lo que significan para los LLMs en general.
- [BLOOM por BigScience](https://www.notion.so/ColossalAI-Community-Wiki-2e5f0c64d1474e669b5de68e8d6839ff): P√°gina de Notion que describe c√≥mo se construy√≥ el modelo BLOOM, con mucha informaci√≥n √∫til sobre la parte de ingenier√≠a y los problemas que se encontraron.
- [OPT-175 Logbook por Meta](https://colab.research.google.com/drive/19kJlxv34mDQVWJhqR6xkC8eHpxaVZJFZ): Registros de investigaci√≥n que muestran lo que sali√≥ mal y lo que sali√≥ bien. √ötil si est√°s planeando preentrenar un modelo de lenguaje muy grande (en este caso, 175B de par√°metros).
- [LLM 360](https://llm360.ai/): Un marco para LLMs de c√≥digo abierto con c√≥digo de entrenamiento y preparaci√≥n de datos, datos, m√©tricas y modelos.

## 4. Ajuste Fino Supervisado

Los modelos preentrenados solo est√°n entrenados en una tarea de predicci√≥n de siguiente token, por lo que no son asistentes √∫tiles. SFT te permite ajustarlos para responder a instrucciones. Adem√°s, te permite ajustar fino tu modelo en cualquier dato (privado, no visto por GPT-4, etc.) y usarlo sin tener que pagar por una API como la de OpenAI.

### Ajuste fino completo:

El ajuste fino completo se refiere a entrenar todos los par√°metros en el modelo. No es una t√©cnica eficiente, pero produce resultados ligeramente mejores.

### LoRA:

Una t√©cnica eficiente en par√°metros (PEFT) basada en adaptadores de bajo rango. En lugar de entrenar todos los par√°metros, solo entrenamos estos adaptadores.

### QLoRA:

Otra PEFT basada en LoRA, que tambi√©n cuantifica los pesos del modelo en 4 bits e introduce optimizadores paginados para manejar picos de memoria. Comb√≠nalo con Unsloth para ejecutarlo de manera eficiente en un cuaderno Colab gratuito.

### Axolotl:

Una herramienta de ajuste fino poderosa y f√°cil de usar que se utiliza en muchos modelos de c√≥digo abierto de √∫ltima generaci√≥n.

### DeepSpeed:

Preentrenamiento y ajuste fino eficientes de LLMs para configuraciones multi-GPU y multi-nodo (implementado en Axolotl).

#### üìö Referencias:

- [La Gu√≠a del Novato para Entrenar LLM por Alpin](https://towardsdatascience.com/the-complete-newbie-guide-to-train-gpt-3-5-8e8a6bd7f35a): Visi√≥n general de los conceptos principales y par√°metros a considerar al ajustar fino LLMs.
- [Perspectivas de LoRA por Sebastian Raschka](https://sebastianraschka.com/Articles/2021_lora_perspectives.html): Perspectivas pr√°cticas sobre LoRA y c√≥mo seleccionar los mejores par√°metros.
- [Ajusta Fino Tu Propio Modelo Llama 2](https://github.com/huggingface/transformers/blob/master/examples/pytorch/language-modeling/run_megatron_gpt2.py): Tutorial pr√°ctico sobre c√≥mo ajustar fino un modelo Llama 2 usando las librer√≠as de Hugging Face.
- [Rellenando Modelos de Lenguaje Grandes por Benjamin Marie](https://huggingface.co/blog/how-to-generate): Mejores pr√°cticas para rellenar ejemplos de entrenamiento para LLMs causales
- [Una Gu√≠a para Principiantes sobre Ajuste Fino de LLM](https://github.com/huggingface/transformers/blob/master/examples/pytorch/text-classification/run_glue.py): Tutorial sobre c√≥mo ajustar fino un modelo CodeLlama usando Axolotl.


# 5. Aprendizaje por Refuerzo a partir de Retroalimentaci√≥n Humana

Despu√©s del ajuste fino supervisado, RLHF es un paso utilizado para alinear las respuestas del LLM con las expectativas humanas. La idea es aprender preferencias a partir de retroalimentaci√≥n humana (o artificial), que se puede usar para reducir sesgos, censurar modelos o hacerlos actuar de manera m√°s √∫til. Es m√°s complejo que SFT y a menudo se considera opcional.

## Conjuntos de datos de preferencia:

Estos conjuntos de datos t√≠picamente contienen varias respuestas con alg√∫n tipo de clasificaci√≥n, lo que los hace m√°s dif√≠ciles de producir que los conjuntos de datos de instrucciones.

## Optimizaci√≥n de Pol√≠ticas Proximales:

Este algoritmo aprovecha un modelo de recompensa que predice si un texto dado est√° altamente clasificado por humanos. Esta predicci√≥n se utiliza luego para optimizar el modelo SFT con una penalizaci√≥n basada en la divergencia KL.

## Optimizaci√≥n de Preferencias Directas:

DPO simplifica el proceso al reformularlo como un problema de clasificaci√≥n. Utiliza un modelo de referencia en lugar de un modelo de recompensa (sin entrenamiento necesario) y solo requiere un hiperpar√°metro, lo que lo hace m√°s estable y eficiente.

#### üìö Referencias:

- [Una Introducci√≥n al Entrenamiento de LLM usando RLHF por Ayush Thakur](link-aqu√≠): Explica por qu√© RLHF es deseable para reducir sesgos y aumentar el rendimiento en LLMs.
- [Ilustraci√≥n RLHF por Hugging Face](link-aqu√≠): Introducci√≥n a RLHF con entrenamiento de modelo de recompensa y ajuste fino con aprendizaje por refuerzo.
- [StackLLaMA por Hugging Face](link-aqu√≠): Tutorial para alinear eficientemente un modelo LLaMA con RLHF usando la librer√≠a transformers.
- [Entrenamiento LLM: RLHF y Sus Alternativas por Sebastian Rashcka](link-aqu√≠): Visi√≥n general del proceso RLHF y alternativas como RLAIF.
- [Ajusta Fino Mistral-7b con DPO](link-aqu√≠): Tutorial para ajustar fino un modelo Mistral-7b con DPO y reproducir NeuralHermes-2.5.

# 6. Evaluaci√≥n

Evaluar LLMs es una parte subestimada del pipeline, que consume tiempo y es moderadamente confiable. Tu tarea espec√≠fica debe dictar lo que quieres evaluar, pero siempre recuerda la ley de Goodhart: "Cuando una medida se convierte en un objetivo, deja de ser una buena medida."

## M√©tricas tradicionales:

M√©tricas como la perplejidad y la puntuaci√≥n BLEU no son tan populares como lo fueron porque est√°n defectuosas en la mayor√≠a de los contextos. A√∫n es importante entenderlas y cu√°ndo pueden ser aplicadas.

## Benchmarks generales:

Basado en el Language Model Evaluation Harness, el Open LLM Leaderboard es el benchmark principal para LLMs de prop√≥sito general (como ChatGPT). Hay otros benchmarks populares como BigBench, MT-Bench, etc.

## Benchmarks espec√≠ficos de tareas:

Tareas como la resumen, traducci√≥n y respuesta a preguntas tienen benchmarks dedicados, m√©tricas e incluso subdominios (m√©dico, financiero, etc.), como PubMedQA para la respuesta a preguntas biom√©dicas.

## Evaluaci√≥n humana:

La evaluaci√≥n m√°s confiable es la tasa de aceptaci√≥n por usuarios o comparaciones hechas por humanos. Si quieres saber si un modelo rinde bien, la forma m√°s simple pero segura es usarlo t√∫ mismo.

#### üìö Referencias:

- [Perplejidad de modelos de longitud fija por Hugging Face](link-aqu√≠): Visi√≥n general de la perplejidad con c√≥digo para implementarla con la librer√≠a transformers.
- [BLEU bajo tu propio riesgo por Rachael Tatman](link-aqu√≠): Visi√≥n general de la puntuaci√≥n BLEU y sus muchos problemas con ejemplos.
- [Una Encuesta sobre Evaluaci√≥n de LLMs por Chang et al.](link-aqu√≠): Papel comprensivo sobre qu√© evaluar, d√≥nde evaluar y c√≥mo evaluar.
- [Chatbot Arena Leaderboard por lmsys](link-aqu√≠): Clasificaci√≥n Elo de LLMs de prop√≥sito general, basada en comparaciones hechas por humanos.

# 7. Cuantificaci√≥n

La cuantificaci√≥n es el proceso de convertir los pesos (y activaciones) de un modelo usando una precisi√≥n m√°s baja. Por ejemplo, los pesos almacenados usando 16 bits pueden ser convertidos en una representaci√≥n de 4 bits. Esta t√©cnica se ha vuelto cada vez m√°s importante para reducir los costos computacionales y de memoria asociados con LLMs.

## T√©cnicas base:

Aprende los diferentes niveles de precisi√≥n (FP32, FP16, INT8, etc.) y c√≥mo realizar cuantificaci√≥n ingenua con t√©cnicas de absmax y punto cero.

## GGUF y llama.cpp:

Dise√±ados originalmente para ejecutarse en CPUs, llama.cpp y el formato GGUF se han convertido en las herramientas m√°s populares para ejecutar LLMs en hardware de grado consumidor.

## GPTQ y EXL2:

GPTQ y, m√°s espec√≠ficamente, el formato EXL2 ofrecen una velocidad incre√≠ble pero solo pueden ejecutarse en GPUs. Los modelos tambi√©n tardan mucho en ser cuantificados.

## AWQ:

Este nuevo formato es m√°s preciso que GPTQ (menor perplejidad) pero usa mucha m√°s VRAM y no es necesariamente m√°s r√°pido.

#### üìö Referencias:

- [Introducci√≥n a la cuantificaci√≥n](link-aqu√≠): Visi√≥n general de la cuantificaci√≥n, cuantificaci√≥n absmax y punto cero, y LLM.int8() con c√≥digo.
- [Cuantificar modelos Llama con llama.cpp](link-aqu√≠): Tutorial sobre c√≥mo cuantificar un modelo Llama 2 usando llama.cpp y el formato GGUF.
- [Cuantificaci√≥n de LLM de 4 bits con GPTQ](link-aqu√≠): Tutorial sobre c√≥mo cuantificar un LLM usando el algoritmo GPTQ con AutoGPTQ.
- [ExLlamaV2: La Biblioteca M√°s R√°pida para Ejecutar LLMs](link-aqu√≠): Gu√≠a sobre c√≥mo cuantificar un modelo Mistral usando el formato EXL2 y ejecutarlo con la biblioteca ExLlamaV2.
- [Entendiendo la Cuantificaci√≥n de Pesos Consciente de Activaci√≥n por FriendliAI](link-aqu√≠): Visi√≥n general de la t√©cnica AWQ y sus beneficios.

# 8. Nuevas Tendencias

## Incrustaciones posicionales:

Aprende c√≥mo los LLMs codifican posiciones, especialmente esquemas de codificaci√≥n posicional relativa como RoPE. Implementa YaRN (multiplica la matriz de atenci√≥n por un factor de temperatura) o ALiBi (penalizaci√≥n de atenci√≥n basada en la distancia de tokens) para extender la longitud del contexto.

## Fusi√≥n de modelos:

Fusionar modelos entrenados se ha convertido en una forma popular de crear modelos performantes sin ning√∫n ajuste fino. La popular biblioteca mergekit implementa los m√©todos de fusi√≥n m√°s populares, como SLERP, DARE y TIES.

## Mezcla de Expertos:

Mixtral repopulariz√≥ la arquitectura MoE gracias a su excelente rendimiento. En paralelo, un tipo de frankenMoE surgi√≥ en la comunidad OSS fusionando modelos como Phixtral, que es una opci√≥n m√°s barata y performante.

## Modelos multimodales:

Estos modelos (como CLIP, Stable Diffusion o LLaVA) procesan m√∫ltiples tipos de entradas (texto, im√°genes, audio, etc.) con un espacio de incrustaci√≥n unificado, lo que desbloquea aplicaciones poderosas como texto-a-imagen.

#### üìö Referencias:

- [Extendiendo el RoPE por EleutherAI](link-aqu√≠): Art√≠culo que resume las diferentes t√©cnicas de codificaci√≥n posicional.
- [Entendiendo YaRN por Rajat Chawla](link-aqu√≠): Introducci√≥n a YaRN.
- [Fusionar LLMs con mergekit](link-aqu√≠): Tutorial sobre fusi√≥n de modelos usando mergekit.
- [Mezcla de Expertos Explicada por Hugging Face](link-aqu√≠): Gu√≠a exhaustiva sobre MoEs y c√≥mo funcionan.
- [Modelos Multimodales Grandes por Chip Huyen](link-aqu√≠): Visi√≥n general de sistemas multimodales y la historia reciente de este campo.

